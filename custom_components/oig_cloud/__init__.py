"""The OIG Cloud integration."""

from __future__ import annotations

import logging
import hashlib
import re
from typing import Any, Dict

from homeassistant import config_entries, core
from homeassistant.config_entries import ConfigEntry
from homeassistant.const import Platform
from homeassistant.core import HomeAssistant
from homeassistant.exceptions import ConfigEntryNotReady

from .lib.oig_cloud_client.api.oig_cloud_api import OigCloudApi
from .const import (
    CONF_NO_TELEMETRY,
    CONF_USERNAME,
    CONF_PASSWORD,
    DOMAIN,
    CONF_STANDARD_SCAN_INTERVAL,
    CONF_EXTENDED_SCAN_INTERVAL,
    CONF_AUTO_MODE_SWITCH,
    CONF_AUTO_MODE_PLAN,
)
from .oig_cloud_coordinator import OigCloudCoordinator
from .data_source import (
    DataSourceController,
    DATA_SOURCE_CLOUD_ONLY,
    DEFAULT_DATA_SOURCE_MODE,
    DEFAULT_PROXY_STALE_MINUTES,
    DEFAULT_LOCAL_EVENT_DEBOUNCE_MS,
    get_data_source_state,
    init_data_source_state,
)

# OPRAVA: Bezpeƒçn√Ω import BalancingManager s try/except
try:
    from .balancing import BalancingManager

    _LOGGER_TEMP = logging.getLogger(__name__)
    _LOGGER_TEMP.debug("oig_cloud: BalancingManager import OK")
except Exception as err:
    BalancingManager = None
    _LOGGER_TEMP = logging.getLogger(__name__)
    _LOGGER_TEMP.error(
        "oig_cloud: Failed to import BalancingManager: %s", err, exc_info=True
    )

_LOGGER = logging.getLogger(__name__)

PLATFORMS: list[Platform] = [Platform.SENSOR]

# OPRAVA: Definujeme v≈°echny mo≈æn√© box modes pro konzistenci
ALL_BOX_MODES = ["Home 1", "Home 2", "Home 3", "Home UPS", "Home 5", "Home 6"]


def _ensure_data_source_option_defaults(hass: HomeAssistant, entry: ConfigEntry) -> None:
    defaults = {
        "data_source_mode": DEFAULT_DATA_SOURCE_MODE,
        "local_proxy_stale_minutes": DEFAULT_PROXY_STALE_MINUTES,
        "local_event_debounce_ms": DEFAULT_LOCAL_EVENT_DEBOUNCE_MS,
    }

    options = dict(entry.options)
    updated = False
    for key, default in defaults.items():
        if options.get(key) is None:
            options[key] = default
            updated = True

    if updated:
        hass.config_entries.async_update_entry(entry, options=options)


def _infer_box_id_from_local_entities(hass: HomeAssistant) -> str | None:
    """Best-effort inference of box_id from existing oig_local entity_ids.

    Expected local entity_id pattern: sensor.oig_local_<box_id>_<suffix>
    """
    try:
        from homeassistant.helpers import entity_registry as er

        reg = er.async_get(hass)
        ids: set[str] = set()
        pat = re.compile(r"^sensor\\.oig_local_(\\d+)_")
        for ent in reg.entities.values():
            m = pat.match(ent.entity_id)
            if m:
                ids.add(m.group(1))
        if len(ids) == 1:
            return next(iter(ids))
        return None
    except Exception:
        return None


def _ensure_planner_option_defaults(hass: HomeAssistant, entry: ConfigEntry) -> None:
    """Ensure new planner-related options exist on legacy config entries."""

    defaults = {
        "battery_planner_mode": "hybrid_autonomy",
        "enable_autonomous_preview": True,
        CONF_AUTO_MODE_SWITCH: False,
        CONF_AUTO_MODE_PLAN: "autonomy",
        "enable_cheap_window_ups": True,
        "cheap_window_percentile": 30,
        "cheap_window_max_intervals": 20,
        "cheap_window_soc_guard_kwh": 0.5,
        "autonomy_soc_step_kwh": 0.5,
        "autonomy_target_penalty": 0.5,
        "autonomy_min_penalty": 2.0,
        "autonomy_negative_export_penalty": 50.0,
    }

    options = dict(entry.options)
    missing_keys = [key for key in defaults.keys() if entry.options.get(key) is None]
    updated = False

    for key, default in defaults.items():
        if options.get(key) is None:
            options[key] = default
            updated = True

    # Migrace star≈°√≠ch hodnot na nov√© vyv√°≈æen√© defaulty
    if options.get("autonomy_min_penalty") in (15.0, 8.0):
        options["autonomy_min_penalty"] = defaults["autonomy_min_penalty"]
        updated = True
    if options.get("autonomy_target_penalty") == 3.0:
        options["autonomy_target_penalty"] = defaults["autonomy_target_penalty"]
        updated = True
    if updated:
        _LOGGER.info(
            "üîß Injecting missing planner options for entry %s: %s",
            entry.entry_id,
            ", ".join(missing_keys) if missing_keys else "none",
        )
        hass.config_entries.async_update_entry(entry, options=options)


async def async_setup(hass: HomeAssistant, config: Dict[str, Any]) -> bool:
    """Set up OIG Cloud integration."""
    _ = config
    _LOGGER.debug("OIG Cloud setup: starting")

    # OPRAVA: Odstran√≠me neexistuj√≠c√≠ import setup_telemetry
    # Initialize telemetry - telemetrie se inicializuje p≈ô√≠mo v ServiceShield
    _LOGGER.debug("OIG Cloud setup: telemetry will be initialized in ServiceShield")

    # OPRAVA: ServiceShield se inicializuje pouze v async_setup_entry, ne zde
    # V async_setup pouze p≈ôiprav√≠me glob√°ln√≠ strukturu
    hass.data.setdefault(DOMAIN, {})
    _LOGGER.debug("OIG Cloud setup: global data structure prepared")

    # OPRAVA: Univerz√°ln√≠ registrace statick√Ωch cest pro v≈°echny verze HA
    await _register_static_paths(hass)

    # OPRAVA: Odstranƒõn√≠ vol√°n√≠ _setup_frontend_panel z async_setup
    # Panel se registruje a≈æ v async_setup_entry kde m√°me p≈ô√≠stup k entry
    # await _setup_frontend_panel(hass)  # ODSTRANƒöNO

    _LOGGER.debug("OIG Cloud setup: completed")
    return True


async def _register_static_paths(hass: HomeAssistant) -> None:
    """Registrace statick√Ωch cest pro HA 2024.5+."""
    static_path = "/oig_cloud_static"
    directory = hass.config.path("custom_components/oig_cloud/www")

    _LOGGER.info("Registering static path: %s -> %s", static_path, directory)

    # OPRAVA: Pouze modern√≠ metoda
    from homeassistant.components.http import StaticPathConfig

    static_config = StaticPathConfig(static_path, directory, cache_headers=False)
    await hass.http.async_register_static_paths([static_config])
    _LOGGER.info("‚úÖ Static paths registered successfully")


async def _setup_frontend_panel(hass: HomeAssistant, entry: ConfigEntry) -> None:
    """Nastaven√≠ frontend panelu (pouze kdy≈æ je povolen)."""
    try:
        # Unik√°tn√≠ ID panelu pro tuto instanci
        panel_id = f"oig_cloud_dashboard_{entry.entry_id}"

        # OPRAVA: inverter_sn mus√≠ b√Ωt numerick√© box_id (nikdy ne helper kl√≠ƒçe jako "spot_prices")
        inverter_sn = None
        try:
            opt_box = entry.options.get("box_id")
            if isinstance(opt_box, str) and opt_box.isdigit():
                inverter_sn = opt_box
        except Exception:
            inverter_sn = None

        coordinator_data = hass.data.get(DOMAIN, {}).get(entry.entry_id, {}).get("coordinator")
        if inverter_sn is None and coordinator_data:
            try:
                from .oig_cloud_sensor import resolve_box_id

                resolved = resolve_box_id(coordinator_data)
                if isinstance(resolved, str) and resolved.isdigit():
                    inverter_sn = resolved
            except Exception:
                inverter_sn = None

        if inverter_sn is None:
            inverter_sn = "unknown"
            _LOGGER.warning(
                "Dashboard setup: Unable to resolve numeric inverter_sn/box_id, using 'unknown'"
            )
        else:
            _LOGGER.info("Dashboard setup: Using inverter_sn = %s", inverter_sn)

        panel_title = (
            f"OIG Dashboard ({inverter_sn})"
            if inverter_sn != "unknown"
            else "OIG Cloud Dashboard"
        )

        # Cache-busting: P≈ôidat verzi + timestamp k URL pro vymaz√°n√≠ browseru cache
        import os
        import json
        import time

        manifest_path = os.path.join(os.path.dirname(__file__), "manifest.json")
        version = "unknown"
        try:
            # OPRAVA: Pou≈æ√≠t async file read m√≠sto blocking open()
            manifest_data = await hass.async_add_executor_job(
                lambda: open(manifest_path, "r").read()
            )
            manifest = json.loads(manifest_data)
            version = manifest.get("version", "unknown")
        except Exception as e:
            _LOGGER.warning("Could not load version from manifest: %s", e)

        # P≈ôidat timestamp pro cache-busting p≈ôi ka≈æd√©m restartu
        cache_bust = int(time.time())

        # OPRAVA: P≈ôidat parametry vƒçetnƒõ v= a t= pro cache-busting
        dashboard_url = f"/oig_cloud_static/dashboard.html?entry_id={entry.entry_id}&inverter_sn={inverter_sn}&v={version}&t={cache_bust}"

        _LOGGER.info("Dashboard URL: %s", dashboard_url)

        from homeassistant.components import frontend

        # OPRAVA: Kontrola existence funkce a jej√≠ vol√°n√≠ bez await pokud vrac√≠ None
        if hasattr(frontend, "async_register_built_in_panel"):
            register_func = getattr(frontend, "async_register_built_in_panel")
            if callable(register_func):
                try:
                    # OPRAVA: Pou≈æ√≠t keyword argumenty pro spr√°vn√© vol√°n√≠
                    # Signature: (hass, component_name, sidebar_title, sidebar_icon,
                    #             sidebar_default_visible, frontend_url_path, config, require_admin)
                    result = register_func(
                        hass,
                        "iframe",  # component_name
                        sidebar_title=panel_title,
                        sidebar_icon="mdi:solar-power",
                        frontend_url_path=panel_id,
                        config={"url": dashboard_url},
                        require_admin=False,
                    )

                    # Pokud funkce vrac√≠ coroutine, await it
                    if hasattr(result, "__await__"):
                        await result

                    _LOGGER.info("‚úÖ Panel '%s' registered successfully", panel_title)
                except Exception as reg_error:
                    _LOGGER.error("Error during panel registration: %s", reg_error)
                    raise
            else:
                _LOGGER.warning("async_register_built_in_panel is not callable")
        else:
            _LOGGER.warning("Frontend async_register_built_in_panel not available")

        # OPRAVA: Debug logov√°n√≠ dostupn√Ωch entit
        coordinator = hass.data[DOMAIN][entry.entry_id].get("coordinator")
        if coordinator and coordinator.data:
            entity_count = len(
                [
                    k
                    for k in hass.states.async_entity_ids()
                    if k.startswith(f"sensor.oig_{inverter_sn}")
                ]
            )
            _LOGGER.info(
                f"Dashboard: Found {entity_count} OIG entities for inverter {inverter_sn}"
            )

            # Kontrola kl√≠ƒçov√Ωch entit (pouze pokud jsou zapnut√© v konfiguraci)
            key_entities = [
                f"sensor.oig_{inverter_sn}_remaining_usable_capacity",  # v≈ædy
            ]

            # P≈ôidat solar_forecast pouze pokud je zapnut√Ω
            if entry.options.get("enable_solar_forecast", False):
                key_entities.append(f"sensor.oig_{inverter_sn}_solar_forecast")

            # P≈ôidat battery_forecast pouze pokud je zapnut√Ω
            if entry.options.get("enable_battery_prediction", False):
                key_entities.append(f"sensor.oig_{inverter_sn}_battery_forecast")

            for entity_id in key_entities:
                entity_state = hass.states.get(entity_id)
                if entity_state:
                    _LOGGER.debug(
                        f"Dashboard entity check: {entity_id} = {entity_state.state}"
                    )
                else:
                    # DEBUG m√≠sto WARNING - entity m≈Ø≈æe chybƒõt p≈ôi startu (timing issue)
                    _LOGGER.debug("Dashboard entity not yet available: %s", entity_id)
        else:
            _LOGGER.warning("Dashboard: No coordinator data for entity checking")

    except Exception as e:
        _LOGGER.error("Failed to setup frontend panel: %s", e)


async def _remove_frontend_panel(hass: HomeAssistant, entry: ConfigEntry) -> None:
    """Odebr√°n√≠ frontend panelu."""
    try:
        panel_id = f"oig_cloud_dashboard_{entry.entry_id}"

        from homeassistant.components import frontend

        # OPRAVA: D≈Økladnƒõj≈°√≠ kontrola existence panelu
        panels_exist = False
        try:
            # Zkus√≠me z√≠skat p≈ô√≠stup k registrovan√Ωm panel≈Øm
            if hasattr(hass, "components") and "frontend" in hass.components:
                frontend_component = hass.components.frontend
                if hasattr(frontend_component, "async_register_built_in_panel"):
                    # Panel syst√©m je dostupn√Ω
                    panels_exist = True
        except Exception:
            pass

        if not panels_exist:
            _LOGGER.debug(
                f"Frontend panel system not available, skipping removal of {panel_id}"
            )
            return

        # OPRAVA: Kontrola existence panelu p≈ôed odstranƒõn√≠m
        try:
            # Pokus√≠me se z√≠skat informace o panelu p≈ôed jeho odstranƒõn√≠m
            # T√≠m ovƒõ≈ô√≠me, ≈æe skuteƒçnƒõ existuje
            panel_exists = False

            if hasattr(hass.data.get("frontend_panels", {}), panel_id):
                panel_exists = True
            elif hasattr(hass.data.get("frontend", {}), "panels"):
                existing_panels = hass.data["frontend"].panels
                panel_exists = panel_id in existing_panels

            if not panel_exists:
                _LOGGER.debug("Panel %s doesn't exist, nothing to remove", panel_id)
                return
        except Exception as check_error:
            _LOGGER.debug(
                f"Cannot check panel existence, proceeding with removal attempt: {check_error}"
            )

        # Pokus o odebr√°n√≠ panelu
        if hasattr(frontend, "async_remove_panel") and callable(
            getattr(frontend, "async_remove_panel")
        ):
            try:
                await frontend.async_remove_panel(hass, panel_id)
                _LOGGER.info("‚úÖ Panel removed: %s", panel_id)
            except ValueError as ve:
                if "unknown panel" in str(ve).lower():
                    _LOGGER.debug(
                        f"Panel {panel_id} was already removed or never existed"
                    )
                else:
                    _LOGGER.warning("Error removing panel %s: {ve}", panel_id)
            except Exception as re:
                _LOGGER.debug("Panel removal handled (panel may not exist): %s", re)
        else:
            _LOGGER.debug("async_remove_panel not available")

    except Exception as e:
        # OPRAVA: V≈°echny chyby logujeme jako debug, proto≈æe jsou oƒçek√°van√©
        _LOGGER.debug("Panel removal handled gracefully: %s", e)


async def _migrate_entity_unique_ids(hass: HomeAssistant, entry: ConfigEntry) -> None:  # noqa: C901
    """Migrace unique_id a cleanup duplicitn√≠ch entit s _2, _3, atd."""
    _LOGGER.info("üîç Starting _migrate_entity_unique_ids function...")
    from homeassistant.helpers import entity_registry as er
    import re

    entity_registry = er.async_get(hass)

    # Najdeme v≈°echny OIG entity pro tento config entry
    entities = er.async_entries_for_config_entry(entity_registry, entry.entry_id)
    _LOGGER.info(f"üìä Found {len(entities)} entities for config entry")

    migrated_count = 0
    skipped_count = 0
    removed_count = 0
    enabled_count = 0
    renamed_count = 0

    # Projdeme v≈°echny entity a uprav√≠me je
    for entity in entities:
        old_unique_id = entity.unique_id
        entity_id = entity.entity_id
        duplicate_pattern = re.compile(r"^(.+?)(_\d+)$")

        # OPRAVA: P≈ôeskoƒçit bojler senzory - maj√≠ vlastn√≠ form√°t unique_id bez oig_cloud_ prefixu
        # Form√°t: {entry_id}_boiler_{sensor_type}
        if "_boiler_" in old_unique_id:
            skipped_count += 1
            _LOGGER.debug("Skipping boiler sensor (correct format): %s", entity_id)
            continue

        # 1. Pokud m√° entita spr√°vn√Ω form√°t unique_id (oig_cloud_*):
        if old_unique_id.startswith("oig_cloud_"):
            # Zkontrolujeme, jestli entity_id m√° p≈ô√≠ponu, ale unique_id ne
            entity_id_match = duplicate_pattern.match(entity_id)
            if entity_id_match:
                suffix = entity_id_match.group(2)
                base_entity_id = entity_id_match.group(1)

                # Pokud unique_id nem√° p≈ô√≠ponu, ale entity_id ano, p≈ôejmenujeme
                if not old_unique_id.endswith(suffix):
                    try:
                        # Zkus√≠me p≈ôejmenovat entity_id (odstran√≠me p≈ô√≠ponu)
                        entity_registry.async_update_entity(
                            entity_id, new_entity_id=base_entity_id
                        )
                        renamed_count += 1
                        _LOGGER.info(
                            f"üîÑ Renamed entity: {entity_id} -> {base_entity_id}"
                        )
                        entity_id = base_entity_id  # Aktualizujeme pro dal≈°√≠ kontroly
                    except Exception:
                        _LOGGER.warning("‚ö†Ô∏è Failed to rename %s: {e}", entity_id)

            # Pokud je disabled, enable ji
            if entity.disabled_by == er.RegistryEntryDisabler.INTEGRATION:
                try:
                    entity_registry.async_update_entity(entity_id, disabled_by=None)
                    enabled_count += 1
                    _LOGGER.info("‚úÖ Re-enabled correct entity: %s", entity_id)
                except Exception:
                    _LOGGER.warning("‚ö†Ô∏è Failed to enable %s: {e}", entity_id)

            skipped_count += 1
            continue

        # 2. M√° star√Ω form√°t unique_id - pot≈ôebuje migraci
        # Zjist√≠me, jestli entity_id m√° p≈ô√≠ponu _X (znamen√° duplicitu)
        entity_id_match = duplicate_pattern.match(entity_id)

        if entity_id_match:
            suffix = entity_id_match.group(2)  # nap≈ô. "_2", "_3"

            # Pokud unique_id nem√° p≈ô√≠ponu, ale entity_id ano = duplicita
            # Tyto entity SMA≈ΩEME (ne jen disable)
            if not old_unique_id.endswith(suffix):
                try:
                    entity_registry.async_remove(entity_id)
                    removed_count += 1
                    _LOGGER.info(
                        f"üóëÔ∏è Removed duplicate entity: {entity_id} "
                        f"(unique_id={old_unique_id} doesn't match entity_id suffix)"
                    )
                    continue
                except Exception:
                    _LOGGER.warning("‚ö†Ô∏è Failed to remove %s: {e}", entity_id)
                    continue

        # 3. Migrace unique_id na nov√Ω form√°t
        if old_unique_id.startswith("oig_") and not old_unique_id.startswith(
            "oig_cloud_"
        ):
            # Form√°t oig_{boxId}_{sensor} -> oig_cloud_{boxId}_{sensor}
            new_unique_id = f"oig_cloud_{old_unique_id[4:]}"
        else:
            # Form√°t {boxId}_{sensor} -> oig_cloud_{boxId}_{sensor}
            new_unique_id = f"oig_cloud_{old_unique_id}"

        try:
            entity_registry.async_update_entity(entity_id, new_unique_id=new_unique_id)
            migrated_count += 1
            _LOGGER.info(
                f"‚úÖ Migrated entity {entity_id}: {old_unique_id} -> {new_unique_id}"
            )
        except Exception:
            _LOGGER.warning("‚ö†Ô∏è Failed to migrate %s: {e}", entity_id)

        # P≈ôeskoƒç√≠me entity, kter√© u≈æ maj√≠ spr√°vn√Ω form√°t
        if old_unique_id.startswith("oig_cloud_"):
            skipped_count += 1
            continue

        # Migrace form√°t≈Ø unique_id
        if old_unique_id.startswith("oig_") and not old_unique_id.startswith(
            "oig_cloud_"
        ):
            # Form√°t oig_{boxId}_{sensor} -> oig_cloud_{boxId}_{sensor}
            new_unique_id = f"oig_cloud_{old_unique_id[4:]}"
        else:
            # Form√°t {boxId}_{sensor} -> oig_cloud_{boxId}_{sensor}
            new_unique_id = f"oig_cloud_{old_unique_id}"

        try:
            entity_registry.async_update_entity(
                entity.entity_id, new_unique_id=new_unique_id
            )
            migrated_count += 1
            _LOGGER.info(
                f"‚úÖ Migrated entity {entity.entity_id}: {old_unique_id} -> {new_unique_id}"
            )
        except Exception:
            _LOGGER.warning("‚ö†Ô∏è Failed to migrate %s: {e}", entity_id)

    # Summary
    _LOGGER.info(
        f"üìä Migration summary: migrated={migrated_count}, removed={removed_count}, "
        f"renamed={renamed_count}, enabled={enabled_count}, skipped={skipped_count}"
    )

    if removed_count > 0 or migrated_count > 0 or renamed_count > 0:
        message_parts = []

        if renamed_count > 0:
            message_parts.append(
                f"**P≈ôejmenov√°no {renamed_count} entit**\n"
                f"Entity s p≈ô√≠ponami (_2, _3) byly p≈ôejmenov√°ny na spr√°vn√© n√°zvy.\n\n"
            )

        if removed_count > 0:
            message_parts.append(
                f"**Odstranƒõno {removed_count} duplicitn√≠ch entit**\n"
                f"Byly to star√© kolize s nespr√°vn√Ωm unique_id.\n\n"
            )

        if migrated_count > 0:
            message_parts.append(
                f"**Migrov√°no {migrated_count} entit na nov√Ω form√°t unique_id**\n"
                f"V≈°echny OIG entity nyn√≠ pou≈æ√≠vaj√≠ standardn√≠ form√°t `oig_cloud_*`.\n\n"
            )

        if enabled_count > 0:
            message_parts.append(
                f"**Povoleno {enabled_count} spr√°vn√Ωch entit**\n"
                f"Entity s nov√Ωm form√°tem byly znovu aktivov√°ny.\n\n"
            )

        message_parts.append(
            "**Co se stalo:**\n"
            "- Star√© entity se p≈ôeregistrovaly s nov√Ωm unique_id\n"
            "- Duplicity byly odstranƒõny\n"
            "- V≈°echny entity by mƒõly fungovat norm√°lnƒõ\n\n"
            "**Pokud nƒõco nefunguje:**\n"
            "Reload integrace v Nastaven√≠ ‚Üí Za≈ô√≠zen√≠ & Slu≈æby ‚Üí OIG Cloud\n\n"
            "Toto je jednor√°zov√° migrace po aktualizaci integrace."
        )

        await hass.services.async_call(
            "persistent_notification",
            "create",
            {
                "title": "OIG Cloud: Migrace entit dokonƒçena",
                "message": "".join(message_parts),
                "notification_id": "oig_cloud_migration_complete",
            },
        )

    if renamed_count > 0:
        _LOGGER.info("üîÑ Renamed %s entities to correct entity_id", renamed_count)
    if migrated_count > 0:
        _LOGGER.info("üîÑ Migrated %s entities to new unique_id format", migrated_count)
    if removed_count > 0:
        _LOGGER.warning("üóëÔ∏è Removed %s duplicate entities", removed_count)
    if enabled_count > 0:
        _LOGGER.info("‚úÖ Re-enabled %s correct entities", enabled_count)
    if skipped_count > 0:
        _LOGGER.debug(
            "‚è≠Ô∏è Skipped %s entities (already in correct format)", skipped_count
        )


async def _cleanup_invalid_empty_devices(hass: HomeAssistant, entry: ConfigEntry) -> None:
    """Remove clearly-invalid devices (e.g., 'spot_prices', 'unknown') with no entities.

    This is a targeted/safe cleanup to get rid of stale registry entries created by
    older versions when box_id resolution was unstable.
    """
    try:
        from homeassistant.helpers import device_registry as dr
        from homeassistant.helpers import entity_registry as er

        device_registry = dr.async_get(hass)
        entity_registry = er.async_get(hass)

        def _strip_known_suffixes(value: str) -> str:
            for suffix in ("_analytics", "_shield"):
                if value.endswith(suffix):
                    return value[: -len(suffix)]
            return value

        # Non-numeric identifiers used by this integration that are still valid.
        allowlisted_bases = {"oig_bojler"}

        devices = dr.async_entries_for_config_entry(device_registry, entry.entry_id)
        removed: list[str] = []

        for device in devices:
            # Never remove devices that still have entities.
            if er.async_entries_for_device(entity_registry, device.id):
                continue

            id_values = [
                identifier[1]
                for identifier in device.identifiers
                if identifier and identifier[0] == DOMAIN and len(identifier) > 1
            ]
            if not id_values:
                continue

            bases = {_strip_known_suffixes(v) for v in id_values if isinstance(v, str)}
            if not bases:
                continue

            if any(base in allowlisted_bases for base in bases):
                continue

            # If every base is numeric, the device id is valid.
            if all(isinstance(base, str) and base.isdigit() for base in bases):
                continue

            device_registry.async_remove_device(device.id)
            removed.append(device.name or device.id)

        if removed:
            _LOGGER.info(
                "Removed %d stale OIG devices without entities: %s",
                len(removed),
                ", ".join(removed),
            )
    except Exception as err:
        _LOGGER.debug("Device registry cleanup failed (non-critical): %s", err)


async def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:  # noqa: C901
    """Set up OIG Cloud from a config entry."""
    _LOGGER.info("oig_cloud: async_setup_entry started for entry_id=%s", entry.entry_id)
    _LOGGER.info(f"Setting up OIG Cloud entry: {entry.title}")
    _LOGGER.debug(f"Config data keys: {list(entry.data.keys())}")
    _LOGGER.debug(f"Config options keys: {list(entry.options.keys())}")

    # Inject defaults for new planner/autonomy options so legacy setups keep working
    _ensure_planner_option_defaults(hass, entry)
    _ensure_data_source_option_defaults(hass, entry)

    # MIGRACE 1: enable_spot_prices -> enable_pricing
    if "enable_spot_prices" in entry.options:
        _LOGGER.info("üîÑ Migrating enable_spot_prices to enable_pricing")
        new_options = dict(entry.options)

        # Pokud enable_spot_prices byl True, zapneme enable_pricing
        if new_options.get("enable_spot_prices", False):
            new_options["enable_pricing"] = True
            _LOGGER.info("‚úÖ Migrated: enable_spot_prices=True -> enable_pricing=True")

        # Odstran√≠me star√Ω flag
        new_options.pop("enable_spot_prices", None)

        # Aktualizujeme entry
        hass.config_entries.async_update_entry(entry, options=new_options)
        _LOGGER.info("‚úÖ Migration completed - enable_spot_prices removed from config")

    # POZN: Automatick√° migrace entity/device registry p≈ôi startu je rizikov√° (m≈Ø≈æe mazat/rozb√≠jet entity).
    # Pokud je pot≈ôeba cleanup/migrace, dƒõlejme ji explicitnƒõ (script / servis), ne automaticky v setupu.

    # Inicializace hass.data struktury pro tento entry P≈òED pou≈æit√≠m
    hass.data.setdefault(DOMAIN, {})
    hass.data[DOMAIN].setdefault(entry.entry_id, {})

    # Initialize data source state early so coordinator setup can respect local/hybrid modes.
    # Also try to infer box_id from local entities so local mapping works without cloud.
    init_data_source_state(hass, entry)
    try:
        options = dict(entry.options)
        if not options.get("box_id"):
            # Prefer explicit proxy box id sensor (most reliable)
            proxy_box = hass.states.get(
                "sensor.oig_local_oig_proxy_proxy_status_box_device_id"
            )
            if proxy_box and isinstance(proxy_box.state, str) and proxy_box.state.isdigit():
                options["box_id"] = proxy_box.state
                hass.config_entries.async_update_entry(entry, options=options)
                _LOGGER.info("Inferred box_id=%s from proxy sensor", proxy_box.state)
            else:
                inferred = _infer_box_id_from_local_entities(hass)
                if inferred:
                    options["box_id"] = inferred
                    hass.config_entries.async_update_entry(entry, options=options)
                    _LOGGER.info("Inferred box_id=%s from local entities", inferred)
    except Exception as err:
        _LOGGER.debug("Inferring box_id from local entities failed (non-critical): %s", err)

    # OPRAVA: Inicializujeme service_shield jako None p≈ôed try blokem
    service_shield = None

    try:
        # Inicializujeme ServiceShield s entry parametrem
        from .service_shield import ServiceShield

        service_shield = ServiceShield(hass, entry)
        await service_shield.start()

        hass.data[DOMAIN][entry.entry_id]["service_shield"] = service_shield

        _LOGGER.info("ServiceShield inicializov√°n a spu≈°tƒõn")
    except Exception as e:
        _LOGGER.error("ServiceShield nen√≠ dostupn√Ω - obecn√° chyba: %s", e)
        # Pokraƒçujeme bez ServiceShield
        hass.data[DOMAIN][entry.entry_id]["service_shield"] = None
        # OPRAVA: Ujist√≠me se, ≈æe service_shield je None
        service_shield = None

    try:
        # Naƒçten√≠ konfigurace z entry.data nebo entry.options
        username = entry.data.get(CONF_USERNAME) or entry.options.get(CONF_USERNAME)
        password = entry.data.get(CONF_PASSWORD) or entry.options.get(CONF_PASSWORD)

        # Debug log pro diagnostiku
        _LOGGER.debug(f"Username: {'***' if username else 'MISSING'}")
        _LOGGER.debug(f"Password: {'***' if password else 'MISSING'}")

        if not username or not password:
            _LOGGER.error("Username or password is missing from configuration")
            return False

        no_telemetry = entry.data.get(CONF_NO_TELEMETRY, False) or entry.options.get(
            CONF_NO_TELEMETRY, False
        )

        # OPRAVA: Preferuj options p≈ôed data, jen pokud options neexistuj√≠, pou≈æij data nebo default
        standard_scan_interval = entry.options.get(
            "standard_scan_interval"
        ) or entry.data.get(CONF_STANDARD_SCAN_INTERVAL, 30)
        extended_scan_interval = entry.options.get(
            "extended_scan_interval"
        ) or entry.data.get(CONF_EXTENDED_SCAN_INTERVAL, 300)

        _LOGGER.debug(
            f"Using intervals: standard={standard_scan_interval}s, extended={extended_scan_interval}s"
        )

        # DEBUG: DOƒåASNƒö ZAK√ÅZAT telemetrii kv≈Øli probl√©m≈Øm s v√Ωkonem
        # OPRAVA: Telemetrie zp≈Øsobovala nekoneƒçnou smyƒçku
        # if not no_telemetry:
        #     _LOGGER.debug("Telemetry enabled, setting up...")
        #     await _setup_telemetry(hass, username)
        # else:
        #     _LOGGER.debug("Telemetry disabled by configuration")

        _LOGGER.debug("Telemetry handled only by ServiceShield, not main module")

        # NOV√â: Vytvo≈ôen√≠ OigCloudApi a zabalen√≠ do SessionManageru
        oig_api = OigCloudApi(username, password, no_telemetry)

        _LOGGER.debug("Creating session manager wrapper")
        from .api.oig_cloud_session_manager import OigCloudSessionManager

        session_manager = OigCloudSessionManager(oig_api)

        # Respect local/hybrid mode: if local proxy is healthy, do not hit cloud during setup.
        # Session manager will authenticate on-demand if we later fall back to cloud.
        state = get_data_source_state(hass, entry.entry_id)
        should_check_cloud_now = state.effective_mode == DATA_SOURCE_CLOUD_ONLY

        if should_check_cloud_now:
            _LOGGER.debug("Initial authentication via session manager")
            # Session manager zavol√° authenticate() p≈ôi prvn√≠m po≈æadavku,
            # ale provedeme to i zde pro kontrolu p≈ôihla≈°ovac√≠ch √∫daj≈Ø
            await session_manager._ensure_auth()

            # CRITICAL: Check if live data is enabled (actual element present in API response)
            # Stats structure: { "box_id": { "actual": {...}, "settings": {...} } }
            _LOGGER.debug("Kontrola, zda jsou v aplikaci OIG Cloud zapnut√° '≈Ωiv√° data'...")
            try:
                test_stats = await oig_api.get_stats()
                if test_stats:
                    # Get first device data
                    first_device = next(iter(test_stats.values())) if test_stats else None
                    if not first_device or "actual" not in first_device:
                        _LOGGER.error(
                            "‚ùå KRITICK√Å CHYBA: V aplikaci OIG Cloud nejsou zapnut√° '≈Ωiv√° data'! "
                            "API odpovƒõƒè neobsahuje element 'actual'. "
                            "U≈æivatel mus√≠ v mobiln√≠ aplikaci zapnout: Nastaven√≠ ‚Üí P≈ô√≠stup k dat≈Øm ‚Üí ≈Ωiv√° data"
                        )
                        raise ConfigEntryNotReady(
                            "V aplikaci OIG Cloud nejsou zapnut√° '≈Ωiv√° data'. "
                            "Zapnƒõte je v mobiln√≠ aplikaci OIG Cloud (Nastaven√≠ ‚Üí P≈ô√≠stup k dat≈Øm ‚Üí ≈Ωiv√° data) "
                            "a restartujte Home Assistant."
                        )
                    _LOGGER.info(
                        "‚úÖ Kontrola ≈æiv√Ωch dat √∫spƒõ≈°n√° - element 'actual' nalezen v API odpovƒõdi"
                    )
                else:
                    _LOGGER.warning(
                        "API vr√°tilo pr√°zdnou odpovƒõƒè, p≈ôeskakuji kontrolu ≈æiv√Ωch dat"
                    )
            except ConfigEntryNotReady:
                raise
            except Exception as e:
                _LOGGER.warning("Nelze ovƒõ≈ôit stav ≈æiv√Ωch dat: %s", e)
                # Pokraƒçujeme i tak - m≈Ø≈æe j√≠t o doƒçasn√Ω probl√©m s API
        else:
            _LOGGER.info(
                "Local telemetry mode active (configured=%s, local_ok=%s) ‚Äì skipping initial cloud authentication and live-data check",
                state.configured_mode,
                state.local_available,
            )

        # Inicializace koordin√°toru - pou≈æijeme session_manager.api (wrapper)
        coordinator = OigCloudCoordinator(
            hass, session_manager, standard_scan_interval, extended_scan_interval, entry
        )

        # OPRAVA: Poƒçkej na prvn√≠ data p≈ôed vytvo≈ôen√≠m senzor≈Ø
        _LOGGER.debug("Waiting for initial coordinator data...")
        await coordinator.async_config_entry_first_refresh()

        if coordinator.data is None:
            _LOGGER.error("Failed to get initial data from coordinator")
            raise ConfigEntryNotReady("No data received from OIG Cloud API")

        _LOGGER.debug(f"Coordinator data received: {len(coordinator.data)} devices")

        # Persist box_id once so sensors can be initialized without relying on coordinator.data order
        try:
            options = dict(entry.options)
            if not options.get("box_id") and coordinator.data:
                box_id = next(
                    (str(k) for k in coordinator.data.keys() if str(k).isdigit()),
                    None,
                )
                if box_id:
                    options["box_id"] = box_id
                    hass.config_entries.async_update_entry(entry, options=options)
                    _LOGGER.info("Persisted box_id=%s into config entry options", box_id)
        except Exception as err:
            _LOGGER.debug("Persisting box_id failed (non-critical): %s", err)

        # OPRAVA: Inicializace notification manageru se spr√°vn√Ωm error handling
        notification_manager = None
        enable_cloud_notifications = entry.options.get("enable_cloud_notifications", True)
        cloud_active_for_setup = (
            get_data_source_state(hass, entry.entry_id).effective_mode
            == DATA_SOURCE_CLOUD_ONLY
        )
        if enable_cloud_notifications and cloud_active_for_setup:
            try:
                _LOGGER.debug("Initializing notification manager...")
                from .oig_cloud_notification import OigNotificationManager

                # PROBL√âM: Ovƒõ≈ô√≠me, ≈æe pou≈æ√≠v√°me spr√°vn√Ω objekt
                _LOGGER.debug(f"Using API object: {type(oig_api)}")
                _LOGGER.debug(
                    f"API has get_notifications: {hasattr(oig_api, 'get_notifications')}"
                )

                # OPRAVA: Pou≈æ√≠t oig_api objekt (OigCloudApi) m√≠sto jak√©hokoliv jin√©ho
                # NOV√â: Pou≈æ√≠t session_manager.api pro p≈ô√≠stup k underlying API
                notification_manager = OigNotificationManager(
                    hass, session_manager.api, "https://www.oigpower.cz/cez/"
                )

                # Nastav√≠me device_id deterministicky (numerick√Ω box_id)
                device_id = None
                try:
                    opt_box = entry.options.get("box_id")
                    if isinstance(opt_box, str) and opt_box.isdigit():
                        device_id = opt_box
                except Exception:
                    device_id = None
                if device_id is None and coordinator.data and isinstance(coordinator.data, dict):
                    device_id = next(
                        (str(k) for k in coordinator.data.keys() if str(k).isdigit()),
                        None,
                    )
                if device_id:
                    notification_manager.set_device_id(device_id)
                    _LOGGER.debug("Set notification manager device_id to: %s", device_id)

                    # Inicializace Mode Transition Tracker
                    if service_shield:
                        try:
                            from .service_shield import ModeTransitionTracker

                            service_shield.mode_tracker = ModeTransitionTracker(
                                hass, device_id
                            )
                            await service_shield.mode_tracker.async_setup()
                            _LOGGER.info(
                                f"Mode Transition Tracker inicializov√°n pro box {device_id}"
                            )
                        except Exception as tracker_error:
                            _LOGGER.warning(
                                f"Failed to initialize Mode Transition Tracker: {tracker_error}"
                            )
                            # Pokraƒçujeme bez trackeru

                    # OPRAVA: Pou≈æ√≠t nov√Ω API p≈ô√≠stup m√≠sto fetch_notifications_and_status
                    try:
                        await notification_manager.update_from_api()
                        _LOGGER.debug("Initial notification data loaded successfully")
                    except Exception as fetch_error:
                        _LOGGER.warning(
                            f"Failed to fetch initial notifications (API endpoint may not exist): {fetch_error}"
                        )
                        # Pokraƒçujeme bez poƒç√°teƒçn√≠ch notifikac√≠ - API endpoint mo≈æn√° neexistuje

                    # P≈ôipoj notification manager ke koordin√°toru i kdy≈æ fetch selhal
                    # Manager m≈Ø≈æe fungovat pozdƒõji pokud se API oprav√≠
                    coordinator.notification_manager = notification_manager
                    _LOGGER.info(
                        "Notification manager created and attached to coordinator (may not have data yet)"
                    )
                else:
                    _LOGGER.warning(
                        "No device data available, notification manager not initialized"
                    )
                    notification_manager = None

            except Exception as e:
                _LOGGER.warning(
                    f"Failed to setup notification manager (API may not be available): {e}"
                )
                # Pokraƒçujeme bez notification manageru - API endpoint mo≈æn√° neexistuje nebo je nedostupn√Ω
                notification_manager = None
        else:
            _LOGGER.debug(
                "Cloud notifications disabled or cloud not active - skipping notification manager"
            )

        # Inicializace solar forecast (pokud je povolen√°)
        solar_forecast = None
        if entry.options.get("enable_solar_forecast", False):
            try:
                _LOGGER.debug("Initializing solar forecast functionality")
                # Solar forecast se inicializuje p≈ô√≠mo v sensorech, ne zde
                solar_forecast = {"enabled": True, "config": entry.options}
            except Exception as e:
                _LOGGER.error("Chyba p≈ôi inicializaci sol√°rn√≠ p≈ôedpovƒõdi: %s", e)
                solar_forecast = {"enabled": False, "error": str(e)}

        # **OPRAVA: Spr√°vn√© nastaven√≠ statistics pro reload**
        statistics_enabled = entry.options.get("enable_statistics", True)
        _LOGGER.debug("Statistics enabled: %s", statistics_enabled)

        # Analytics device info (service device linked to the main box device)
        # NOTE: box_id mus√≠ b√Ωt numerick√© a stabiln√≠ i v local_only re≈æimu (bez cloud dat).
        try:
            from .oig_cloud_sensor import resolve_box_id

            box_id_for_devices = resolve_box_id(coordinator)
        except Exception:
            box_id_for_devices = entry.options.get("box_id")
        if not (isinstance(box_id_for_devices, str) and box_id_for_devices.isdigit()):
            box_id_for_devices = "unknown"

        analytics_device_info = {
            "identifiers": {(DOMAIN, f"{box_id_for_devices}_analytics")},
            "name": f"Analytics & Predictions {box_id_for_devices}",
            "manufacturer": "OIG",
            "model": "Analytics Module",
            "via_device": (DOMAIN, box_id_for_devices),
            "entry_type": "service",
        }

        # NOV√â: Podpora pro OTE API a spotov√© ceny
        ote_api = None
        if entry.options.get("enable_pricing", False):
            try:
                _LOGGER.debug("Initializing OTE API for spot prices")
                from .api.ote_api import OteApi

                ote_api = OteApi()
                # OPRAVA: Odstranƒõno vol√°n√≠ fetch_spot_prices - data u≈æ jsou v coordinatoru
                _LOGGER.info("OTE API successfully initialized")
            except Exception as e:
                _LOGGER.error("Failed to initialize OTE API: %s", e)
                if ote_api:
                    await ote_api.close()
                ote_api = None
        else:
            _LOGGER.debug("Pricing disabled - skipping OTE API initialization")

        # NOV√â: Bojlerov√Ω modul (pokud je povolen)
        boiler_coordinator = None
        if entry.options.get("enable_boiler", False):
            try:
                _LOGGER.debug("Initializing Boiler module")
                from .boiler.coordinator import BoilerCoordinator

                # Kombinace entry.data a entry.options pro config
                boiler_config = {**entry.data, **entry.options}

                boiler_coordinator = BoilerCoordinator(hass, boiler_config)

                # Prvn√≠ refresh
                await boiler_coordinator.async_config_entry_first_refresh()

                _LOGGER.info("Boiler coordinator successfully initialized")
            except Exception as e:
                _LOGGER.error("Failed to initialize Boiler coordinator: %s", e)
                boiler_coordinator = None
        else:
            _LOGGER.debug("Boiler module disabled")

        # NOV√â: Podm√≠nƒõn√© nastaven√≠ dashboard podle konfigurace
        dashboard_enabled = entry.options.get(
            "enable_dashboard", False
        )  # OPRAVA: default False m√≠sto True
        # OPRAVA: Dashboard registrujeme A≈Ω PO vytvo≈ôen√≠ senzor≈Ø

        # PHASE 3: Inicializace Balancing Manager (refactored - no physics)
        balancing_enabled = entry.options.get("balancing_enabled", True)
        _LOGGER.info("oig_cloud: balancing_enabled=%s", balancing_enabled)

        balancing_manager = None
        if balancing_enabled and BalancingManager is not None:
            try:
                _LOGGER.info("oig_cloud: Initializing BalancingManager")
                # Get box_id deterministicky (entry.options ‚Üí coordinator numeric keys)
                box_id = None
                try:
                    opt_box = entry.options.get("box_id")
                    if isinstance(opt_box, str) and opt_box.isdigit():
                        box_id = opt_box
                except Exception:
                    box_id = None

                if box_id is None and coordinator.data and isinstance(coordinator.data, dict):
                    box_id = next(
                        (str(k) for k in coordinator.data.keys() if str(k).isdigit()),
                        None,
                    )

                if not box_id:
                    _LOGGER.warning("oig_cloud: No box_id available for BalancingManager")

                storage_path = hass.config.path(".storage")

                balancing_manager = BalancingManager(hass, box_id, storage_path, entry)
                await balancing_manager.async_setup()

                _LOGGER.info("oig_cloud: BalancingManager successfully initialized")

                # Periodick√© vol√°n√≠ balancingu (check every 30min)
                from homeassistant.helpers.event import (
                    async_track_time_interval,
                    async_call_later,
                )
                from datetime import timedelta

                async def update_balancing(_now: Any) -> None:
                    """Periodick√° kontrola balancingu."""
                    _LOGGER.debug("BalancingManager: periodic check_balancing()")
                    try:
                        await balancing_manager.check_balancing()
                    except Exception as e:
                        _LOGGER.error(f"Error checking balancing: {e}", exc_info=True)

                # Aktualizace ka≈æd√Ωch 30 minut
                entry.async_on_unload(
                    async_track_time_interval(
                        hass, update_balancing, timedelta(minutes=30)
                    )
                )

                # Prvn√≠ vol√°n√≠ hned p≈ôi startu (po delay aby forecast mƒõl ƒças se inicializovat)
                async def initial_balancing_check(_now: Any) -> None:
                    """Poƒç√°teƒçn√≠ kontrola balancingu po startu."""
                    _LOGGER.debug("BalancingManager: initial check_balancing()")
                    try:
                        result = await balancing_manager.check_balancing()
                        if result:
                            _LOGGER.info(
                                f"‚úÖ Initial check created plan: {result.mode.name}"
                            )
                        else:
                            _LOGGER.debug("Initial check: no plan needed yet")
                    except Exception as e:
                        _LOGGER.error(
                            f"Error in initial balancing check: {e}", exc_info=True
                        )

                # Prvn√≠ kontrola za 2 minuty (aby forecast mƒõl ƒças se inicializovat)
                async_call_later(hass, 120, initial_balancing_check)

            except Exception as err:
                _LOGGER.error(
                    "oig_cloud: Failed to initialize BalancingManager: %s",
                    err,
                    exc_info=True,
                )
                balancing_manager = None
        else:
            if not balancing_enabled:
                _LOGGER.info("oig_cloud: BalancingManager disabled via config options")
            if BalancingManager is None:
                _LOGGER.warning(
                    "oig_cloud: BalancingManager not available (import failed)"
                )

        # Ulo≈æen√≠ dat do hass.data
        hass.data[DOMAIN][entry.entry_id] = {
            "coordinator": coordinator,
            "session_manager": session_manager,  # NOV√â: Ulo≈æit session manager
            "notification_manager": notification_manager,
            "data_source_controller": None,
            "data_source_state": get_data_source_state(hass, entry.entry_id),
            "solar_forecast": solar_forecast,
            "statistics_enabled": statistics_enabled,
            "analytics_device_info": analytics_device_info,
            "service_shield": service_shield,
            "ote_api": ote_api,
            "boiler_coordinator": boiler_coordinator,  # NOV√â: Boiler coordinator
            "balancing_manager": balancing_manager,  # PHASE 3: Refactored Balancing Manager
            "dashboard_enabled": dashboard_enabled,  # NOV√â: stav dashboard
            "config": {
                "enable_statistics": statistics_enabled,
                "enable_pricing": entry.options.get("enable_pricing", False),
                "enable_boiler": entry.options.get("enable_boiler", False),  # NOV√â
                "enable_dashboard": dashboard_enabled,  # NOV√â
            },
        }

        # Data source controller (cloud/hybrid/local with proxy health fallback)
        try:
            data_source_controller = DataSourceController(hass, entry, coordinator)
            await data_source_controller.async_start()
            hass.data[DOMAIN][entry.entry_id]["data_source_controller"] = (
                data_source_controller
            )
        except Exception as err:
            _LOGGER.warning("DataSourceController start failed (non-critical): %s", err)

        # OPRAVA: P≈ôid√°n√≠ ServiceShield dat do glob√°ln√≠ho √∫lo≈æi≈°tƒõ pro senzory
        if service_shield:
            # Vytvo≈ô√≠me glob√°ln√≠ odkaz na ServiceShield pro senzory
            hass.data[DOMAIN]["shield"] = service_shield

            # Vytvo≈ô√≠me device info pro ServiceShield (per-box service device)
            try:
                from .oig_cloud_sensor import resolve_box_id

                shield_box_id = resolve_box_id(coordinator)
            except Exception:
                shield_box_id = entry.options.get("box_id")
            if not (isinstance(shield_box_id, str) and shield_box_id.isdigit()):
                shield_box_id = "unknown"
            shield_device_info = {
                "identifiers": {(DOMAIN, f"{shield_box_id}_shield")},
                "name": f"ServiceShield {shield_box_id}",
                "manufacturer": "OIG",
                "model": "Shield",
                "via_device": (DOMAIN, shield_box_id),
                "entry_type": "service",
            }
            hass.data[DOMAIN][entry.entry_id]["shield_device_info"] = shield_device_info

            _LOGGER.debug("ServiceShield data prepared for sensors")

            # OPRAVA: P≈ôid√°n√≠ debug logov√°n√≠ pro ServiceShield stav
            _LOGGER.info(f"ServiceShield status: {service_shield.get_shield_status()}")
            _LOGGER.info(f"ServiceShield queue info: {service_shield.get_queue_info()}")

        # POZN: Pln√° migrace/cleanup device registry je rizikov√° (m≈Ø≈æe rozb√≠t entity).
        # Dƒõl√°me jen bezpeƒçn√Ω √∫klid pr√°zdn√Ωch za≈ô√≠zen√≠ s neplatn√Ωm box_id (nap≈ô. spot_prices/unknown).

        # V≈ædy registrovat sensor platform
        await hass.config_entries.async_forward_entry_setups(entry, ["sensor"])

        # Targeted cleanup for stale/invalid devices (e.g., 'spot_prices', 'unknown')
        # that can be left behind after unique_id/device_id stabilization.
        hass.async_create_task(_cleanup_invalid_empty_devices(hass, entry))

        # OPRAVA: Dashboard registrujeme a≈æ TERAZ - po vytvo≈ôen√≠ v≈°ech senzor≈Ø A POUZE pokud je enabled
        if dashboard_enabled:
            await _setup_frontend_panel(hass, entry)
            _LOGGER.info("OIG Cloud Dashboard panel enabled and registered")
        else:
            await _remove_frontend_panel(hass, entry)
            _LOGGER.info(
                "OIG Cloud Dashboard panel disabled - panel not registered"
            )  # OPRAVA: lep≈°√≠ log message

        # P≈ôid√°me listener pro zmƒõny konfigurace - OPRAVEN callback na async funkci
        entry.async_on_unload(entry.add_update_listener(async_update_options))

        # Async importy pro vyhn√°n√≠ se blokov√°n√≠ event loopu
        from .services import (
            async_setup_services,
            async_setup_entry_services_with_shield,
        )

        # Setup z√°kladn√≠ch slu≈æeb (pouze jednou pro celou integraci)
        if len([k for k in hass.data[DOMAIN].keys() if k != "shield"]) == 1:
            await async_setup_services(hass)

        # Setup entry-specific slu≈æeb s shield ochranou
        # OPRAVA: P≈ôed√°n√≠ service_shield p≈ô√≠mo, ne z hass.data
        await async_setup_entry_services_with_shield(hass, entry, service_shield)

        # NOV√â: Registrace HTTP API endpoint≈Ø pro boiler
        if boiler_coordinator:
            from .boiler.api_views import register_boiler_api_views

            register_boiler_api_views(hass)
            _LOGGER.info("Boiler API endpoints registered")

        # NOV√â: Registrace Planning API endpoint≈Ø
        from .api.planning_api import setup_planning_api_views

        setup_planning_api_views(hass)
        _LOGGER.info("Planning API endpoints registered")

        # NOV√â: Registrace OIG Cloud REST API endpoint≈Ø pro heavy data
        # (timeline, spot prices, analytics)
        try:
            from .api.ha_rest_api import setup_api_endpoints

            setup_api_endpoints(hass)
            _LOGGER.info("‚úÖ OIG Cloud REST API endpoints registered successfully")
        except Exception as e:
            _LOGGER.error(
                f"Failed to register OIG Cloud REST API endpoints: {e}", exc_info=True
            )
            # Pokraƒçujeme i bez API - senzory budou fungovat s attributes

        # OPRAVA: Zajistit, ≈æe ServiceShield je p≈ôipojen√Ω k vol√°n√≠ slu≈æeb
        if service_shield:
            _LOGGER.info(
                "ServiceShield je aktivn√≠ a p≈ôipraven√Ω na interceptov√°n√≠ slu≈æeb"
            )
            # Test interceptu - simulace vol√°n√≠ pro debug
            _LOGGER.debug(f"ServiceShield pending: {len(service_shield.pending)}")
            _LOGGER.debug(f"ServiceShield queue: {len(service_shield.queue)}")
            _LOGGER.debug(f"ServiceShield running: {service_shield.running}")

            # OPRAVA: Explicitn√≠ spu≈°tƒõn√≠ monitorov√°n√≠
            _LOGGER.debug("Ovƒõ≈ôuji, ≈æe ServiceShield monitoring bƒõ≈æ√≠...")

            # P≈ôid√°me test callback pro ovƒõ≈ôen√≠ funkƒçnosti
            async def test_shield_monitoring(_now: Any) -> None:
                status = service_shield.get_shield_status()
                queue_info = service_shield.get_queue_info()
                _LOGGER.debug(
                    f"[OIG Shield] Test monitoring tick - pending: {len(service_shield.pending)}, queue: {len(service_shield.queue)}, running: {service_shield.running}"
                )
                _LOGGER.debug("[OIG Shield] Status: %s", status)
                _LOGGER.debug("[OIG Shield] Queue info: %s", queue_info)

                # OPRAVA: Debug telemetrie - uk√°≈æeme co by se odes√≠lalo
                if service_shield.telemetry_handler:
                    _LOGGER.debug("[OIG Shield] Telemetry handler je aktivn√≠")
                    if hasattr(service_shield, "_log_telemetry"):
                        _LOGGER.debug(
                            "[OIG Shield] Telemetry logging metoda je dostupn√°"
                        )
                else:
                    _LOGGER.debug("[OIG Shield] Telemetry handler nen√≠ aktivn√≠")

            # Registrujeme test callback na krat≈°√≠ interval pro debug
            from homeassistant.helpers.event import async_track_time_interval
            from datetime import timedelta

            entry.async_on_unload(
                async_track_time_interval(
                    hass, test_shield_monitoring, timedelta(seconds=30)
                )
            )

        else:
            _LOGGER.warning("ServiceShield nen√≠ dostupn√Ω - slu≈æby nebudou chr√°nƒõny")

        # OPRAVA: ODSTRANƒöN√ç duplicitn√≠ registrace slu≈æeb - zp≈Øsobovala p≈ôeps√°n√≠ spr√°vn√©ho sch√©matu
        # Slu≈æby se u≈æ registrovaly v√Ω≈°e v async_setup_entry_services_with_shield
        # await services.async_setup_services(hass)  # ODSTRANƒöNO
        # await services.async_setup_entry_services(hass, entry)  # ODSTRANƒöNO

        _LOGGER.debug("OIG Cloud integration setup complete")
        return True

    except Exception as e:
        _LOGGER.error(f"Error initializing OIG Cloud: {e}", exc_info=True)
        raise ConfigEntryNotReady(f"Error initializing OIG Cloud: {e}") from e


async def _setup_telemetry(hass: core.HomeAssistant, username: str) -> None:
    """Setup telemetry if enabled."""
    try:
        _LOGGER.debug("Starting telemetry setup...")

        email_hash = hashlib.sha256(username.encode("utf-8")).hexdigest()
        hass_id = hashlib.sha256(hass.data["core.uuid"].encode("utf-8")).hexdigest()

        _LOGGER.debug(
            f"Telemetry identifiers - Email hash: {email_hash[:16]}..., HASS ID: {hass_id[:16]}..."
        )

        # P≈ôesuneme import do async executor aby neblokoval event loop
        def _import_and_setup_telemetry() -> Any:
            try:
                _LOGGER.debug("Importing REST telemetry modules...")
                from .shared.logging import setup_otel_logging

                _LOGGER.debug("Setting up REST telemetry logging...")
                handler = setup_otel_logging(email_hash, hass_id)

                # P≈ôid√°me handler do root loggeru pro OIG Cloud
                oig_logger = logging.getLogger("custom_components.oig_cloud")
                oig_logger.addHandler(handler)
                oig_logger.setLevel(logging.DEBUG)

                _LOGGER.debug(
                    f"Telemetry handler attached to logger: {oig_logger.name}"
                )
                _LOGGER.info("REST telemetry successfully initialized")

                return handler
            except Exception as e:
                _LOGGER.error(f"Error in telemetry setup executor: {e}", exc_info=True)
                raise

        await hass.async_add_executor_job(_import_and_setup_telemetry)
        _LOGGER.debug("REST telemetry setup completed via executor")

        # Test log pro ovƒõ≈ôen√≠ funkƒçnosti
        _LOGGER.info("TEST: Telemetry test message - this should appear in New Relic")

    except Exception as e:
        _LOGGER.warning(f"Failed to setup telemetry: {e}", exc_info=True)
        # Pokraƒçujeme bez telemetrie


async def async_unload_entry(
    hass: HomeAssistant, entry: config_entries.ConfigEntry
) -> bool:
    """Unload a config entry."""
    # Odebr√°n√≠ dashboard panelu p≈ôi unload
    await _remove_frontend_panel(hass, entry)

    # PHASE 3: Cleanup Balancing Manager (no async_shutdown needed - just storage)

    # NOV√â: Cleanup session manageru
    if DOMAIN in hass.data and entry.entry_id in hass.data[DOMAIN]:
        data_source_controller = hass.data[DOMAIN][entry.entry_id].get(
            "data_source_controller"
        )
        if data_source_controller:
            try:
                await data_source_controller.async_stop()
            except Exception as err:
                _LOGGER.debug("DataSourceController stop failed: %s", err)

        session_manager = hass.data[DOMAIN][entry.entry_id].get("session_manager")
        if session_manager:
            _LOGGER.debug("Closing session manager")
            await session_manager.close()

    unload_ok = await hass.config_entries.async_unload_platforms(entry, ["sensor"])
    if unload_ok:
        hass.data[DOMAIN].pop(entry.entry_id, None)
    return unload_ok


async def async_remove_config_entry_device(
    hass: HomeAssistant, config_entry: ConfigEntry, device_entry: Any
) -> bool:
    """Allow removing stale devices created by this integration.

    Home Assistant calls this when the user tries to delete a device from the UI.
    We only allow removing devices that have no entities.
    """
    _ = config_entry
    try:
        from homeassistant.helpers import entity_registry as er

        entity_registry = er.async_get(hass)
        if er.async_entries_for_device(entity_registry, device_entry.id):
            return False
        # Allow removal for both current and legacy identifier domains.
        # Legacy versions used separate identifier domains:
        # - "oig_cloud_analytics"
        # - "oig_cloud_shield"
        allowed_domains = {DOMAIN, f"{DOMAIN}_analytics", f"{DOMAIN}_shield"}
        return any(identifier[0] in allowed_domains for identifier in device_entry.identifiers)
    except Exception:
        return False


async def async_reload_entry(config_entry: config_entries.ConfigEntry) -> None:
    """Reload config entry."""
    hass = config_entry.hass
    await async_unload_entry(hass, config_entry)
    await async_setup_entry(hass, config_entry)


async def async_update_options(
    hass: HomeAssistant, config_entry: config_entries.ConfigEntry
) -> None:
    """Update options with dashboard management."""
    old_options = config_entry.options
    new_options = dict(config_entry.options)

    # Kontrola zmƒõny dashboard nastaven√≠
    old_dashboard_enabled = old_options.get("enable_dashboard", False)
    new_dashboard_enabled = new_options.get("enable_dashboard", False)

    _LOGGER.debug(
        f"Dashboard options update: old={old_dashboard_enabled}, new={new_dashboard_enabled}"
    )

    if old_dashboard_enabled != new_dashboard_enabled:
        _LOGGER.info(
            f"Dashboard setting changed: {old_dashboard_enabled} -> {new_dashboard_enabled}"
        )

        if new_dashboard_enabled:
            # Zapnut√≠ dashboard
            await _setup_frontend_panel(hass, config_entry)
            _LOGGER.info("Dashboard panel enabled")
        else:
            # Vypnut√≠ dashboard
            await _remove_frontend_panel(hass, config_entry)
            _LOGGER.info("Dashboard panel disabled")

        # Aktualizace dat v hass.data
        if DOMAIN in hass.data and config_entry.entry_id in hass.data[DOMAIN]:
            hass.data[DOMAIN][config_entry.entry_id][
                "dashboard_enabled"
            ] = new_dashboard_enabled
            hass.data[DOMAIN][config_entry.entry_id]["config"][
                "enable_dashboard"
            ] = new_dashboard_enabled
    else:
        # P≈òID√ÅNO: I kdy≈æ se hodnota nezmƒõnila, ujist√≠me se ≈æe panel nen√≠ registrov√°n pokud je disabled
        if not new_dashboard_enabled:
            await _remove_frontend_panel(hass, config_entry)
            _LOGGER.debug("Ensuring dashboard panel is not registered (disabled)")

    # Pokud byla oznaƒçena pot≈ôeba reload, proveƒè ho
    if new_options.get("_needs_reload"):
        new_options.pop("_needs_reload", None)
        hass.config_entries.async_update_entry(config_entry, options=new_options)
        hass.async_create_task(hass.config_entries.async_reload(config_entry.entry_id))
    else:
        hass.config_entries.async_update_entry(config_entry, options=new_options)


async def _cleanup_unused_devices(hass: HomeAssistant, entry: ConfigEntry) -> None:
    """Vyƒçi≈°tƒõn√≠ nepou≈æ√≠van√Ωch za≈ô√≠zen√≠."""
    try:
        from homeassistant.helpers import device_registry as dr
        from homeassistant.helpers import entity_registry as er

        device_registry = dr.async_get(hass)
        entity_registry = er.async_get(hass)

        # Najdeme v≈°echna za≈ô√≠zen√≠ pro tuto integraci
        devices = dr.async_entries_for_config_entry(device_registry, entry.entry_id)

        devices_to_remove = []
        for device in devices:
            device_name = device.name or ""
            should_keep = True

            # Definujeme pravidla pro zachov√°n√≠ za≈ô√≠zen√≠
            keep_patterns = [
                "OIG.*Statistics",  # Star√© statistiky (regex pattern)
                "ƒåEZ Battery Box",
                "OIG Cloud Home",
                "Analytics & Predictions",
                "ServiceShield",
            ]
            for pattern in keep_patterns:
                if pattern in device_name:
                    should_keep = True
                    break
            else:
                # Pokud neodpov√≠d√° keep patterns, zkontrolujeme remove patterns

                # Zkontrolujeme, jestli za≈ô√≠zen√≠ odpov√≠d√° keep patterns
                for pattern in keep_patterns:
                    if re.search(pattern, device_name):
                        should_keep = False
                        break
                else:
                    # Pokud nem√° ≈æ√°dn√© entity, m≈Ø≈æeme smazat
                    device_entities = er.async_entries_for_device(
                        entity_registry, device.id
                    )
                    if not device_entities:
                        should_keep = False

            if not should_keep:
                devices_to_remove.append(device)
                _LOGGER.info(
                    f"Marking device for removal: {device.name} (ID: {device.id})"
                )
            else:
                _LOGGER.debug(f"Keeping device: {device.name} (ID: {device.id})")

        # Sma≈æeme nepou≈æ√≠van√° za≈ô√≠zen√≠
        for device in devices_to_remove:
            try:
                _LOGGER.info(f"Removing unused device: {device.name} (ID: {device.id})")
                device_registry.async_remove_device(device.id)
            except Exception as e:
                _LOGGER.warning("Error removing device {device.id}: %s", e)

        if devices_to_remove:
            _LOGGER.info(f"Removed {len(devices_to_remove)} unused devices")
        else:
            _LOGGER.debug("No unused devices found to remove")
    except Exception as e:
        _LOGGER.warning("Error cleaning up devices: %s", e)
